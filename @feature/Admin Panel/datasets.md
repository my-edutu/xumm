# Feature: Dataset Archive & Batch Management

## ðŸ“ The Journey
Once tasks are completed, they are bundled into "Batches." The `Datasets` module is the repository where these batches are quality-checked and prepared for the marketplace.

### Engineering Decisions
- **Batch State Logic**: Batches move through a pipeline: `Processing` -> `Reviewing` -> `Archived` (Ready for Sale).
- **Quality Benchmarking**: Large-scale view of average accuracy across a batch of 10,000+ submissions.
- **Linguasense Dataset Packaging**: Specifically identifies and bundles high-priority linguistic datasets for cultural AI projects.
- **Archive Explorer**: A searchable historical record of every data batch ever generated by the network.

## ðŸ’» Implementation Details
- **File**: `admin-panel/src/App.tsx`
- **Component**: `Datasets()`.

### Technical Parameters
- **Batch Size**: Number of unique data points.
- **Precision Floor**: The minimum accuracy required for the batch to be marketplace-ready.
- **Data Density**: Metrics on the variety of nodes/regions involved in the batch.

## ðŸ§ª Verification
- [x] "Processing" state shows an active animation on the batch card.
- [x] Accuracy bars are color-graded based on the Dataset quality floor.
- [x] Archive searching works across historical batch IDs.
